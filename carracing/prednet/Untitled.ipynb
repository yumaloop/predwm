{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import json\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters for our model. I was using an older tf version, when HParams was not available ...\n",
    "\n",
    "# controls whether we concatenate (z, c, h), etc for features used for car.\n",
    "MODE_ZCH = 0\n",
    "MODE_ZC = 1\n",
    "MODE_Z = 2\n",
    "MODE_Z_HIDDEN = 3 # extra hidden later\n",
    "MODE_ZH = 4\n",
    "\n",
    "HyperParams = namedtuple('HyperParams', ['num_steps',\n",
    "                                         'max_seq_len',\n",
    "                                         'input_seq_width',\n",
    "                                         'output_seq_width',\n",
    "                                         'rnn_size',\n",
    "                                         'batch_size',\n",
    "                                         'grad_clip',\n",
    "                                         'num_mixture',\n",
    "                                         'learning_rate',\n",
    "                                         'decay_rate',\n",
    "                                         'min_learning_rate',\n",
    "                                         'use_layer_norm',\n",
    "                                         'use_recurrent_dropout',\n",
    "                                         'recurrent_dropout_prob',\n",
    "                                         'use_input_dropout',\n",
    "                                         'input_dropout_prob',\n",
    "                                         'use_output_dropout',\n",
    "                                         'output_dropout_prob',\n",
    "                                         'is_training',\n",
    "                                        ])\n",
    "\n",
    "def default_hps():\n",
    "    return HyperParams(num_steps=2000, # train model for 2000 steps.\n",
    "                     max_seq_len=1000, # train on sequences of 100\n",
    "                     input_seq_width=35, # width of our data (32 + 3 actions)\n",
    "                     output_seq_width=32, # width of our data is 32\n",
    "                     rnn_size=256, # number of rnn cells\n",
    "                     batch_size=100, # minibatch sizes\n",
    "                     grad_clip=1.0, # \n",
    "                     num_mixture=5, # number of mixtures in MDN\n",
    "                     learning_rate=0.001,\n",
    "                     decay_rate=1.0,\n",
    "                     min_learning_rate=0.00001,\n",
    "                     use_layer_norm=0, # set this to 1 to get more stable results (less chance of NaN), but slower\n",
    "                     use_recurrent_dropout=0,\n",
    "                     recurrent_dropout_prob=0.90,\n",
    "                     use_input_dropout=0,\n",
    "                     input_dropout_prob=0.90,\n",
    "                     use_output_dropout=0,\n",
    "                     output_dropout_prob=0.90,\n",
    "                     is_training=1)\n",
    "\n",
    "hps_model = default_hps()\n",
    "hps_sample = hps_model._replace(batch_size=1, max_seq_len=1, use_recurrent_dropout=0, is_training=0) # replace params as default settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MDN-RNN model\n",
    "class MDNRNN():\n",
    "    def __init__(self, hps, gpu_mode=True, reuse=False):\n",
    "        self.hps = hps\n",
    "        with tf.variable_scope('mdn_rnn', reuse=reuse):\n",
    "            if not gpu_mode:\n",
    "                with tf.device(\"/cpu:0\"):\n",
    "                    print(\"model using cpu\")\n",
    "                    self.g = tf.Graph()\n",
    "                    with self.g.as_default():\n",
    "                        self.build_model(hps)\n",
    "            else:\n",
    "                print(\"model using gpu\")\n",
    "                self.g = tf.Graph()\n",
    "                with self.g.as_default():\n",
    "                    self.build_model(hps)\n",
    "        self.init_session()\n",
    "        \n",
    "    def build_model(self, hps):\n",
    "        self.num_mixture = hps.num_mixture\n",
    "        KMIX = self.num_mixture # 5 mixtures (5 classes)\n",
    "        INWIDTH = hps.input_seq_width # 35 channels\n",
    "        OUTWIDTH = hps.output_seq_width # 32 channels\n",
    "        LENGTH = self.hps.max_seq_len # 1000 timesteps\n",
    "\n",
    "        if hps.is_training:\n",
    "            self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "        cell_fn = tf.contrib.rnn.LayerNormBasicLSTMCell # use LayerNormLSTM\n",
    "\n",
    "        use_recurrent_dropout = False if self.hps.use_recurrent_dropout == 0 else True\n",
    "        use_input_dropout = False if self.hps.use_input_dropout == 0 else True\n",
    "        use_output_dropout = False if self.hps.use_output_dropout == 0 else True\n",
    "        is_training = False if self.hps.is_training == 0 else True\n",
    "        use_layer_norm = False if self.hps.use_layer_norm == 0 else True\n",
    "\n",
    "        if use_recurrent_dropout:\n",
    "            cell = cell_fn(hps.rnn_size, layer_norm=use_layer_norm, dropout_keep_prob=self.hps.recurrent_dropout_prob)\n",
    "        else:\n",
    "            cell = cell_fn(hps.rnn_size, layer_norm=use_layer_norm)\n",
    "\n",
    "        # multi-layer, and dropout:\n",
    "        print(\"input dropout mode =\", use_input_dropout)\n",
    "        print(\"output dropout mode =\", use_output_dropout)\n",
    "        print(\"recurrent dropout mode =\", use_recurrent_dropout)\n",
    "        \n",
    "        if use_input_dropout:\n",
    "            print(\"applying dropout to input with keep_prob =\", self.hps.input_dropout_prob)\n",
    "            cell = tf.contrib.rnn.DropoutWrapper(cell, input_keep_prob=self.hps.input_dropout_prob)\n",
    "        if use_output_dropout:\n",
    "            print(\"applying dropout to output with keep_prob =\", self.hps.output_dropout_prob)\n",
    "            cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=self.hps.output_dropout_prob)\n",
    "        self.cell = cell\n",
    "\n",
    "        self.sequence_lengths = LENGTH # assume every sample has same length.\n",
    "        self.input_x = tf.placeholder(dtype=tf.float32, shape=[self.hps.batch_size, self.hps.max_seq_len, INWIDTH])\n",
    "        self.output_x = tf.placeholder(dtype=tf.float32, shape=[self.hps.batch_size, self.hps.max_seq_len, OUTWIDTH])\n",
    "\n",
    "        actual_input_x = self.input_x\n",
    "        self.initial_state = cell.zero_state(batch_size=hps.batch_size, dtype=tf.float32) \n",
    "\n",
    "        NOUT = OUTWIDTH * KMIX * 3\n",
    "\n",
    "        with tf.variable_scope('RNN'):\n",
    "            output_w = tf.get_variable(\"output_w\", [self.hps.rnn_size, NOUT])\n",
    "            output_b = tf.get_variable(\"output_b\", [NOUT])\n",
    "\n",
    "        output, last_state = tf.nn.dynamic_rnn(cell, actual_input_x, initial_state=self.initial_state, \n",
    "                                               time_major=False, swap_memory=True, dtype=tf.float32, scope=\"RNN\")\n",
    "\n",
    "        output = tf.reshape(output, [-1, hps.rnn_size])\n",
    "        output = tf.nn.xw_plus_b(output, output_w, output_b)\n",
    "        output = tf.reshape(output, [-1, KMIX * 3])\n",
    "        self.final_state = last_state    \n",
    "\n",
    "        logSqrtTwoPI = np.log(np.sqrt(2.0 * np.pi))\n",
    "\n",
    "        def tf_lognormal(y, mean, logstd):\n",
    "            return -0.5 * ((y - mean) / tf.exp(logstd)) ** 2 - logstd - logSqrtTwoPI\n",
    "\n",
    "        def get_lossfunc(logmix, mean, logstd, y):\n",
    "            v = logmix + tf_lognormal(y, mean, logstd)\n",
    "            v = tf.reduce_logsumexp(v, 1, keepdims=True)\n",
    "            return -tf.reduce_mean(v)\n",
    "\n",
    "        def get_mdn_coef(output):\n",
    "            logmix, mean, logstd = tf.split(output, 3, 1)\n",
    "            logmix = logmix - tf.reduce_logsumexp(logmix, 1, keepdims=True)\n",
    "            return logmix, mean, logstd\n",
    "\n",
    "        out_logmix, out_mean, out_logstd = get_mdn_coef(output)\n",
    "\n",
    "        self.out_logmix = out_logmix\n",
    "        self.out_mean = out_mean\n",
    "        self.out_logstd = out_logstd\n",
    "\n",
    "        # reshape target data so that it is compatible with prediction shape\n",
    "        flat_target_data = tf.reshape(self.output_x,[-1, 1])\n",
    "        lossfunc = get_lossfunc(out_logmix, out_mean, out_logstd, flat_target_data)\n",
    "        \n",
    "        self.cost = tf.reduce_mean(lossfunc)\n",
    "\n",
    "        if self.hps.is_training == 1:\n",
    "            self.lr = tf.Variable(self.hps.learning_rate, trainable=False)\n",
    "            optimizer = tf.train.AdamOptimizer(self.lr)\n",
    "\n",
    "            gvs = optimizer.compute_gradients(self.cost)\n",
    "            capped_gvs = [(tf.clip_by_value(grad, -self.hps.grad_clip, self.hps.grad_clip), var) for grad, var in gvs]\n",
    "            self.train_op = optimizer.apply_gradients(capped_gvs, global_step=self.global_step, name='train_step')\n",
    "\n",
    "        # initialize vars\n",
    "        self.init = tf.global_variables_initializer()\n",
    "\n",
    "        t_vars = tf.trainable_variables()\n",
    "        self.assign_ops = {}\n",
    "        for var in t_vars:\n",
    "            #if var.name.startswith('mdn_rnn'):\n",
    "            pshape = var.get_shape()\n",
    "            pl = tf.placeholder(tf.float32, pshape, var.name[:-2]+'_placeholder')\n",
    "            assign_op = var.assign(pl)\n",
    "            self.assign_ops[var] = (assign_op, pl)\n",
    "        \n",
    "    def init_session(self):\n",
    "        \"\"\"Launch TensorFlow session and initialize variables\"\"\"\n",
    "        self.sess = tf.Session(graph=self.g)\n",
    "        self.sess.run(self.init)\n",
    "        \n",
    "    def close_sess(self):\n",
    "        \"\"\" Close TensorFlow session \"\"\"\n",
    "        self.sess.close()\n",
    "        \n",
    "    def get_model_params(self):\n",
    "        # get trainable params.\n",
    "        model_names = []\n",
    "        model_params = []\n",
    "        model_shapes = []\n",
    "\n",
    "        with self.g.as_default():\n",
    "            t_vars = tf.trainable_variables()\n",
    "            for var in t_vars:\n",
    "                #if var.name.startswith('mdn_rnn'):\n",
    "                param_name = var.name\n",
    "                p = self.sess.run(var)\n",
    "                model_names.append(param_name)\n",
    "                params = np.round(p*10000).astype(np.int).tolist()\n",
    "                model_params.append(params)\n",
    "                model_shapes.append(p.shape)\n",
    "        return model_params, model_shapes, model_names\n",
    "    \n",
    "    def get_random_model_params(self, stdev=0.5):\n",
    "        # get random params.\n",
    "        _, mshape, _ = self.get_model_params()\n",
    "        rparam = []\n",
    "        for s in mshape:\n",
    "            #rparam.append(np.random.randn(*s)*stdev)\n",
    "            rparam.append(np.random.standard_cauchy(s)*stdev) # spice things up\n",
    "        return rparam\n",
    "    \n",
    "    def set_random_params(self, stdev=0.5):\n",
    "        rparam = self.get_random_model_params(stdev)\n",
    "        self.set_model_params(rparam)\n",
    "        \n",
    "    def set_model_params(self, params):\n",
    "        with self.g.as_default():\n",
    "            t_vars = tf.trainable_variables()\n",
    "            idx = 0\n",
    "            for var in t_vars:\n",
    "                #if var.name.startswith('mdn_rnn'):\n",
    "                pshape = tuple(var.get_shape().as_list())\n",
    "                p = np.array(params[idx])\n",
    "                assert pshape == p.shape, \"inconsistent shape\"\n",
    "                assign_op, pl = self.assign_ops[var]\n",
    "                self.sess.run(assign_op, feed_dict={pl.name: p/10000.})\n",
    "                idx += 1\n",
    "                \n",
    "    def load_json(self, jsonfile='rnn.json'):\n",
    "        with open(jsonfile, 'r') as f:\n",
    "            params = json.load(f)\n",
    "        self.set_model_params(params)\n",
    "    \n",
    "    def save_json(self, jsonfile='rnn.json'):\n",
    "        model_params, model_shapes, model_names = self.get_model_params()\n",
    "        qparams = []\n",
    "        for p in model_params:\n",
    "            qparams.append(p)\n",
    "        with open(jsonfile, 'wt') as outfile:\n",
    "            json.dump(qparams, outfile, sort_keys=True, indent=0, separators=(',', ': '))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model using gpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0913 13:33:51.540109 139905944487680 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0913 13:33:51.558022 139905944487680 deprecation.py:506] From /home/uchiumi/.local/lib/python3.5/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0913 13:33:51.570032 139905944487680 deprecation.py:323] From <ipython-input-3-1215638afbfc>:69: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dropout mode = False\n",
      "output dropout mode = False\n",
      "recurrent dropout mode = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0913 13:33:51.868859 139905944487680 deprecation.py:323] From /home/uchiumi/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:2403: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "rnn = MDNRNN(hps_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.MDNRNN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'assign_ops',\n",
       " 'build_model',\n",
       " 'cell',\n",
       " 'close_sess',\n",
       " 'cost',\n",
       " 'final_state',\n",
       " 'g',\n",
       " 'get_model_params',\n",
       " 'get_random_model_params',\n",
       " 'hps',\n",
       " 'init',\n",
       " 'init_session',\n",
       " 'initial_state',\n",
       " 'input_x',\n",
       " 'load_json',\n",
       " 'num_mixture',\n",
       " 'out_logmix',\n",
       " 'out_logstd',\n",
       " 'out_mean',\n",
       " 'output_x',\n",
       " 'save_json',\n",
       " 'sequence_lengths',\n",
       " 'sess',\n",
       " 'set_model_params',\n",
       " 'set_random_params']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pi_idx(x, pdf):\n",
    "    # samples from a categorial distribution\n",
    "    N = pdf.size\n",
    "    accumulate = 0\n",
    "    for i in range(0, N):\n",
    "        accumulate += pdf[i]\n",
    "        if (accumulate >= x):\n",
    "            return i\n",
    "    print('error with sampling ensemble')\n",
    "    return -1\n",
    "\n",
    "def sample_sequence(sess, s_model, hps, init_z, actions, temperature=1.0, seq_len=1000):\n",
    "    # generates a random sequence using the trained model \n",
    "    OUTWIDTH = hps.output_seq_width\n",
    "    INWIDTH = hps.input_seq_width\n",
    "\n",
    "    prev_x = np.zeros((1, 1, OUTWIDTH))\n",
    "    prev_x[0][0] = init_z\n",
    "    prev_state = sess.run(s_model.initial_state)\n",
    "\n",
    "    '''\n",
    "    if prev_data is not None:\n",
    "    # encode the previous data into the hidden state first\n",
    "    for i in range(prev_data.shape[0]):\n",
    "      prev_x[0][0] = prev_data[i]\n",
    "      feed = {s_model.input_x: prev_x, s_model.initial_state:prev_state}\n",
    "      [next_state] = sess.run([s_model.final_state], feed)\n",
    "      prev_state = next_state\n",
    "    '''\n",
    "\n",
    "    strokes = np.zeros((seq_len, OUTWIDTH), dtype=np.float32)\n",
    "\n",
    "    for i in range(seq_len):\n",
    "        input_x = np.concatenate((prev_x, actions[i].reshape((1, 1, 3))), axis=2)\n",
    "        feed = {s_model.input_x: input_x, s_model.initial_state:prev_state}\n",
    "        [logmix, mean, logstd, next_state] = sess.run([s_model.out_logmix, s_model.out_mean, s_model.out_logstd, s_model.final_state], feed)\n",
    "\n",
    "        # adjust temperatures\n",
    "        logmix2 = np.copy(logmix)/temperature\n",
    "        logmix2 -= logmix2.max()\n",
    "        logmix2 = np.exp(logmix2)\n",
    "        logmix2 /= logmix2.sum(axis=1).reshape(OUTWIDTH, 1)\n",
    "\n",
    "        mixture_idx = np.zeros(OUTWIDTH)\n",
    "        chosen_mean = np.zeros(OUTWIDTH)\n",
    "        chosen_logstd = np.zeros(OUTWIDTH)\n",
    "        \n",
    "        for j in range(OUTWIDTH):\n",
    "            idx = get_pi_idx(np.random.rand(), logmix2[j])\n",
    "            mixture_idx[j] = idx\n",
    "            chosen_mean[j] = mean[j][idx]\n",
    "            chosen_logstd[j] = logstd[j][idx]\n",
    "\n",
    "        rand_gaussian = np.random.randn(OUTWIDTH)*np.sqrt(temperature)\n",
    "        next_x = chosen_mean+np.exp(chosen_logstd)*rand_gaussian\n",
    "\n",
    "        strokes[i,:] = next_x\n",
    "\n",
    "        prev_x[0][0] = next_x\n",
    "        prev_state = next_state\n",
    "\n",
    "    return strokes\n",
    "\n",
    "def rnn_init_state(rnn):\n",
    "    return rnn.sess.run(rnn.initial_state)\n",
    "\n",
    "def rnn_next_state(rnn, z, a, prev_state):\n",
    "    input_x = np.concatenate((z.reshape((1, 1, 32)), a.reshape((1, 1, 3))), axis=2)\n",
    "    feed = {rnn.input_x: input_x, rnn.initial_state:prev_state}\n",
    "    return rnn.sess.run(rnn.final_state, feed)\n",
    "\n",
    "def rnn_output_size(mode):\n",
    "    if mode == MODE_ZCH:\n",
    "        return (32+256+256)\n",
    "    if (mode == MODE_ZC) or (mode == MODE_ZH):\n",
    "        return (32+256)\n",
    "    return 32 # MODE_Z or MODE_Z_HIDDEN\n",
    "\n",
    "def rnn_output(state, z, mode):\n",
    "    if mode == MODE_ZCH:\n",
    "        return np.concatenate([z, np.concatenate((state.c,state.h), axis=1)[0]])\n",
    "    if mode == MODE_ZC:\n",
    "        return np.concatenate([z, state.c[0]])\n",
    "    if mode == MODE_ZH:\n",
    "        return np.concatenate([z, state.h[0]])\n",
    "    return z # MODE_Z or MODE_Z_HIDDEN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
